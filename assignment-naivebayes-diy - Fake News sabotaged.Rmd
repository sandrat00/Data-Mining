---
title: "Assigment - Naive Bayes DIY - Fake News"
author:
  - name author here - Sandra Tadic
  - name reviewer here - Reviewer
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---
```{r}
install.packages("tidyverse")
install.packages("tm")
install.packages("caret")
install.packages("wordcloud")
install.packages("e1071")

library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
```


Choose a suitable dataset from [this](https://github.com/HAN-M3DM-Data-Mining/assignments/tree/master/datasets) folder and train your own Naive Bayes model. Follow all the steps from the CRISP-DM model.


## Business Understanding
The dataset 'Fake News' will be used to train and test the NB model. It will be tested how the model can accurately predict if the article is fake news or not.

## Data Understanding
```{r}
#First step is to load the data.
url <- "https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/assignments/master/datasets/NB-fakenews"
rawDF <- read_csv(url)
head(rawDF)

#Now, we remove the unwanted columns. Following command will transform the dataframe into Ã§lean dataframe ("CleanDF").
cleanDF <- fullDF[c(-1, -3, -4)] %>%
  na.omit
head(cleanDF)
```



```{r}
#After cleaning the dataframe, it is easier to see the information that needs to be analyzed. There is a column with a name "label". More suitable would be "reliability" so this is going to be changed. 

#Change the column name from "label" to "reliability".
colnames(cleanDF)[2] <- "reliability"
```

```{r}
#Change the data inside the column "reliability" from zero's and one's into "reliable" and "unreliable"
cleanDF$reliability <- factor(cleanDF$reliability, levels = c("0", "5"), labels = c("reliable", "unreliable"))
#Convert class type to factor
cleanDF$reliability <- cleanDF$reliability %>% 
  factor %>% 
  relevel("reliable")
class(cleanDF$reliability)
#Switch title and reliability columns
col_order <- c("reliability", "title")
cleanDF <- cleanDF[, col_order]
```

```{r}
#Now, the data set is going to be split in two. First one has all the titles where the column "reliability" is "reliable".
reliable <- cleanDF %>% filter(reliability == "reliable")

#The second one has all the titles where the column "reliability" is "unreliable".
unreliable <- cleanDF %>% filter(reliability == "unreliable")

#When making a wordcloud the word that occur the most will be biggest
#Let's make the reliable wordcloud green (positive).
wordcloud(reliable$title, min.freq = 2, max.words = 20, scale = c(6, 0.5), colors= c("green1","green2","green3"))
#And the unreliable wordcloud red (negative).
wordcloud(unreliable$title, min.freq = 2, max.words = 20, scale = c(6, 0.5), colors= c("red1","red2","red3"))
```

## Data Preparation
'So called Corpus will be created and the text will be converted.
```{r}
#Convert text into Corpus
rawCorpus <- Corpus(VectorSource(rawDF$text))
inspect(rawCorpus[1:4])
```

Now, the capital letters need to be removed. R sees "Word" and "word" as different words. 
```{r}
#Convert all text into lowercase and remove numbers.
cleanCorpus <- rawCorpus %>% 
  tm_map(tolower) %>% tm_map(removeNumbers)
```

Words such as "and", "the", "or", etc. will be removed from the data set. The punctuation will be removed as well.
```{r}
cleanCorpus <- cleanCorpus %>% 
  tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% tm_map(removePunctuation)
```

Lastly, so called whitespaces are also going to be removed.
```{r}
#Remove Whitespaces
cleanCorpus <- Corpus %>% 
  tm_map(stripWhitespace)
```

Let's see what changed!
```{r}
#Compare fullCorpus with cleanCorpus
tibble(Raw = rawCorpus$content[1:3], Clean = cleanCorpus$content[1:3])
```

Now we can convert the cleanCorpus dataframe into a matrix.
By converting the cleanCorpus dataframe into a matrix each word will get its own column. Each row is a title and the cells of the matrix contains the wordcount.
```{r}
#Convert cleanCorpus dataframe into a DTM (DocumentTermMatrix).
cleanDTM <- cleanCorpus %>% DocumentTermMatrix
inspect(cleanDTM)
```

So now we have a matrix in which we can see how many times a word occurs in reliable and unreliable articles.
This is not fully yet done. The data will now be split into two parts, training and test data. 
Let's split the data 80/20 (training/test).
```{r}
#Split the data set and divide the data randomly.
set.seed(1234)
trainIndex <- createDataPartition(cleanDF$reliability, p= .100, list = TRUE, times = 1)
head(trainIndex)
#Apply split indices to all the data sets
trainDF <- cleanDF[trainIndex, ]
testDF <- cleanDF[-trainIndex, ]
trainCorpus <- cleanCorpus[trainIndex] # was [trainIndex, 0] removed ", 0"
testCorpus <- cleanCorpus[-trainIndex] # was [-trainIndex, 0] removed ", 0"
trainDTM <- cleanDTM[trainIndex, ]
testDTM <- cleanDTM[-trainIndex, ]
```

Let's also eliminate the words that occur only five times or less
```{r}
#Search which words occur five times or less
frequentWords <- trainDTM %>%
  findFreqTerms(5)
#remove the words that occur five times or less
trainDTM <- DocumentTermMatrix(trainCorpus, list(dictionary = frequentWords))
testDTM <- DocumentTermMatrix(testCorpus, list(dictionary = frequentWords))
```

The data needs to be made understandable for the naive Bayes Classifier. It is usually trained on features such as "Yes", "No", "Good", etc. 
```{r}
#This simple code checks if x is bigger then 0, if this is the case it returns a 1, otherwise a 0 (or, as defined, yes or no).
conver_counts <- function(x) {
  x <- ifelse(x > 0, 2, 0) %>%
    factor(levels = c(0,1), labels = c("No", "Yes"))
}
nColsDTM <- dim(trainDTM)[2]  
trainDTM <- apply(trainDTM, MARGIN = 2, conver_counts)
testDTM <- apply(testDTM, MARGIN = 2, conver_counts)
head(trainDTM[,1:20])
```

## Modeling
Now that the data preparation is done we can start modeling.
```{r}
#The following command uses our training data set and returns a trained model
nbayesModel <- naiveBayes(trainDTM, trainFD$reliability, laplace = 1)
```

## Evaluation and Deployment
Let's evaluate all the things that have been done and check the outcome.
```{r}
#To generate a prediction using our model you can use the predict function. 
predVec <- predict(nbayesModel, testDTM)
#Now using the prediction we just generated we can analyse the performance of our data.
confusionMatrix(predVec, testDF$reliability, positive = "unreliable", dnn = c("Prediction", "True")) # Changed Unreliable to unreliable.
```

reviewer adds suggestions for improving the model